{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk"
      ],
      "metadata": {
        "id": "1GmhbWFtF6pU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CIR1HD8Gibq",
        "outputId": "a45ccf1e-0956-49a2-e99c-a27bcf32055d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Reviews.csv\", on_bad_lines='skip', engine='python')\n",
        "data=pd.DataFrame(df)"
      ],
      "metadata": {
        "id": "ebFTN4VwGpo3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = df['Text']"
      ],
      "metadata": {
        "id": "mzVlgIcwG505"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews.dropna()"
      ],
      "metadata": {
        "id": "9-T24T8lHCSh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews[:10000]"
      ],
      "metadata": {
        "id": "ZmuNiBt0HRL4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    #\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "reviews = reviews.apply(preprocess)"
      ],
      "metadata": {
        "id": "klEeL5mCHcmK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "VQqkWxlsHqIP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "H_LuQSSdHz0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "reviews_tokens = reviews.apply(tokenize)"
      ],
      "metadata": {
        "id": "63IfID43Hzw5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pos_and_ner(tokens):\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ner_tree = ne_chunk(pos_tags)\n",
        "    return pos_tags, ner_tree"
      ],
      "metadata": {
        "id": "MKonB6TWIuQZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "example_tokens = reviews_tokens.iloc[0]\n",
        "pos_tags, ner_tree = pos_and_ner(example_tokens)\n",
        "\n",
        "print(\"Tokens:\", example_tokens)\n",
        "print(\"\\nPOS Tags:\", pos_tags)\n",
        "print(\"\\nNamed Entity Recognition Tree:\")\n",
        "print(ner_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbkV9VPI08j",
        "outputId": "bdcacd15-6251-482e-bee8-96ba2f758f33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['bought', 'several', 'vitality', 'canned', 'dog', 'food', 'products', 'found', 'good', 'quality', 'product', 'looks', 'like', 'stew', 'processed', 'meat', 'smells', 'better', 'labrador', 'finicky', 'appreciates', 'product', 'better']\n",
            "\n",
            "POS Tags: [('bought', 'VBD'), ('several', 'JJ'), ('vitality', 'NN'), ('canned', 'VBD'), ('dog', 'JJ'), ('food', 'NN'), ('products', 'NNS'), ('found', 'VBD'), ('good', 'JJ'), ('quality', 'NN'), ('product', 'NN'), ('looks', 'VBZ'), ('like', 'IN'), ('stew', 'NN'), ('processed', 'VBN'), ('meat', 'NN'), ('smells', 'NNS'), ('better', 'RBR'), ('labrador', 'NN'), ('finicky', 'JJ'), ('appreciates', 'VBZ'), ('product', 'NN'), ('better', 'RBR')]\n",
            "\n",
            "Named Entity Recognition Tree:\n",
            "(S\n",
            "  bought/VBD\n",
            "  several/JJ\n",
            "  vitality/NN\n",
            "  canned/VBD\n",
            "  dog/JJ\n",
            "  food/NN\n",
            "  products/NNS\n",
            "  found/VBD\n",
            "  good/JJ\n",
            "  quality/NN\n",
            "  product/NN\n",
            "  looks/VBZ\n",
            "  like/IN\n",
            "  stew/NN\n",
            "  processed/VBN\n",
            "  meat/NN\n",
            "  smells/NNS\n",
            "  better/RBR\n",
            "  labrador/NN\n",
            "  finicky/JJ\n",
            "  appreciates/VBZ\n",
            "  product/NN\n",
            "  better/RBR)\n"
          ]
        }
      ]
    }
  ]
}